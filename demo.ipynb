{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c53e6598-dd65-41ba-8fb7-ec1c753e3a31",
   "metadata": {},
   "source": [
    "# Simple RAG Demo\n",
    "\n",
    "It turns out over the past few years, it's become not too difficult to create\n",
    "your own basic ChatGPT-like functionality to talk to!\n",
    "\n",
    "This notebook goes through how to use an LLM with RAG (Retrieval Augemented Generation)!\n",
    "\n",
    "RAG is a way to supplement your LLM chats with your documentation, without\n",
    "going through the time- and computationally-expensive process of training\n",
    "an LLM using your own data.\n",
    "\n",
    "We're going to start with setting up some folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4713241-33b1-46e9-8f27-2323c168fcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here, we're setting defining some folders to use in later stages\n",
    "import os, getpass\n",
    "\n",
    "# this is where downloaded models will be stored\n",
    "# otherwise, they'll fill up your home directory - and they ain't small!\n",
    "huggingface_cache = f'/vast/scratch/users/{getpass.getuser()}/hfcache/'\n",
    "os.environ[\"HF_HOME\"] = huggingface_cache\n",
    "\n",
    "# this is where the embedding database will be stored\n",
    "database_path = f\"/vast/scratch/users/{getpass.getuser()}/chroma\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09548be9-53a0-4580-93bf-7d56bc2021ec",
   "metadata": {},
   "source": [
    "## Choosing your models\n",
    "\n",
    "Now there are a plethora of public LLM models that you can use to create.\n",
    "\n",
    "In this demo, we're using the \"mxbai-embed-large-v1\" model to generate\n",
    "embeddings. This model is general-purpose and is decently powerful.\n",
    "\n",
    "For the chat model, we're using \"Qwn2.5-1.5B-Instruct\" This is a newish\n",
    "model. Importantly, \"1.5B\" indicates the size, and in this case, 1.5B = 1.5 Billion parameters.\n",
    "Sounds like a lot, but the leading models can have more than 100B parameters!\n",
    "\n",
    "We're limited in size here because of the smallish GPU we're using.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cb77825-d73f-4ddc-b025-6a4f26862768",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model_name = \"mixedbread-ai/mxbai-embed-large-v1\"\n",
    "chat_model_name = \"Qwen/Qwen2.5-1.5B-Instruct\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01205f7-a814-4169-83c1-53636f76a034",
   "metadata": {},
   "source": [
    "## Setting up your models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a797d7c-ee87-48fe-a36f-4029fef42db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if on an M* chip mac, you can change \"cuda\" to \"mps\" for acceleration instead\n",
    "# if you don't have a GPU, change \"cuda\" to \"cpu\". Note that some of the steps\n",
    "# below will be veeeery slow if you use \"cpu\"\n",
    "device = \"cuda\" \n",
    "# here, we can specify the length of the answer.\n",
    "tokens = 256 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc96646b-251b-4b51-827f-8d263cbe62cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vast/scratch/users/yang.e/simple-rag-demo/menv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# We need to import some useful functions to automatically download the model\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# A tokenizer is a tool to break-up text into meaningful parts\n",
    "# usually different LLM model architectures only work with a specific tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    chat_model_name, \n",
    ")\n",
    "# Now we're pulling the LLM model! This may take a bit of time.\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    chat_model_name, \n",
    ").to(device) # This is telling us where we want the model computations to perform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fc52493-b26e-4204-bdfe-13a098e9d39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vast/scratch/users/yang.e/simple-rag-demo/menv/lib/python3.11/zoneinfo/_tzpath.py:44: InvalidTZPathWarning: Invalid paths specified in PYTHONTZPATH environment variable. Paths should be absolute but found the following relative paths:\n",
      "    menv/share/zoneinfo\n",
      "    menv/share/tzinfo\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Setting up a text generation pipeline with our downloaded model and tokenizer.\n",
    "from transformers import pipeline\n",
    "from langchain_huggingface.llms import HuggingFacePipeline\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=tokens, device=device, return_full_text=False)\n",
    "hf = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8396d3-2d83-4560-9ab1-ecae213b29e9",
   "metadata": {},
   "source": [
    "Now, we're ready to start talking with our LLM that we downloaded!\n",
    "In a very oversimplified way, an LLM is just a text completion tool.\n",
    "It will try to generate text that probabilistically fits. Let's\n",
    "try asking a question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a02e895-abf3-486e-9f43-e1c50a73fcb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Electroencephalography (EEG) is a diagnostic medical procedure that records the electrical activity of the brain. It involves placing electrodes on the scalp to detect and measure tiny changes in voltage caused by neural signals.\\n\\nHere's how it works:\\n\\n1. Electrodes: Small, flat metal discs called electrodes are attached to the scalp using adhesive tape or clips.\\n2. Recording: The electrodes pick up weak electrical impulses generated by neurons as they transmit messages throughout the brain.\\n3. Amplification: These signals are amplified so that they can be recorded more clearly.\\n4. Analysis: The resulting EEG pattern is analyzed for patterns associated with different types of brain functions and conditions.\\n\\nUses of EEG include:\\n- Diagnosis of epilepsy\\n- Monitoring seizures\\n- Evaluation of sleep disorders\\n- Detection of neurological injuries\\n- Assessment of cognitive function\\n\\nEEG findings may help diagnose various conditions like epilepsy, Parkinson's disease, Alzheimer's disease, and others. However, it should not replace clinical assessment by healthcare professionals.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# e.g., let's supply our question to the model as-is:\n",
    "question = \"Can you tell me what electroencephalography is?\"\n",
    "\n",
    "# this may take awhile as the model will try to generate as much text as it can.\n",
    "hf.invoke(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a45a8d7-272d-44ed-9d80-1ee148f4a82b",
   "metadata": {},
   "source": [
    "We're going to make it more explicit that we want an answer to a question\n",
    "by using a PromptTemplate. This will be more useful later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29b99b84-4145-4aa2-9bba-ae22f757978c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Electroencephalography (EEG) is a non-invasive diagnostic test that measures the electrical activity of the brain. It involves placing electrodes on the scalp to record the electrical signals generated by neurons in the brain. These signals are then analyzed and interpreted to diagnose various neurological conditions, such as epilepsy, Alzheimer's disease, and sleep disorders. EEG can also be used to monitor patients undergoing anesthesia or during surgical procedures. The information provided in this answer is based on general knowledge about EEG and its uses. However, it may not cover all aspects of the topic, including technical details or specific applications of EEG. For more detailed information, I recommend consulting with a medical professional or referring to reliable sources on the subject.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# Create a template as a string\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: \"\"\"\n",
    "\n",
    "# conver the string template into a PromptTemplate object\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# chain the prompt template with the text-generation pipeline\n",
    "chain = prompt | hf\n",
    "\n",
    "# invoke the model, substituting the question into the placeholder\n",
    "print(chain.invoke({\"question\": question}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbae12f-5d81-4076-aecf-2fd2e68dbf59",
   "metadata": {},
   "source": [
    "It seems to answer the question more succinctly now!\n",
    "\n",
    "## Setting up the embedding model\n",
    "\n",
    "The embedding model is a key element of the RAG setup. It is a specialized\n",
    "language model that converts text into \"embeddings\", which are numerical\n",
    "values. Converting text to numerical values is super useful, because it\n",
    "enables us to calculate \"distances\" between text and therefore group similar\n",
    "text together. \n",
    "\n",
    "The concept of creating embeddings from text is not recent (I think it's\n",
    "from the 70s), but the use of trained neural networks to generate embeddings is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5669889d-15ec-4b62-9e4d-ef07f35ecae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we're creating a HuggingFaceEmbeddings object to be used\n",
    "# with our embedding database\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "model_kwargs = {'device': device, \"trust_remote_code\":True,}\n",
    "encode_kwargs = {'normalize_embeddings': True}\n",
    "hf_emb = HuggingFaceEmbeddings(\n",
    "    cache_folder=huggingface_cache,\n",
    "    model_name=embedding_model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2ce799c-6e93-4427-8319-c8f7e7469514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we're creating an on-disk database to store our embeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "# assigning an embedding function makes the database\n",
    "# more convenient to use!\n",
    "db = Chroma(\n",
    "    persist_directory=database_path, \n",
    "    embedding_function=hf_emb \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7d0891-c144-4840-b17d-3c87f5618416",
   "metadata": {},
   "source": [
    "# Converting PDFs to embeddings\n",
    "\n",
    "We've now downloaded an embedding model and pushed it to the GPU.\n",
    "And then, we initialized a database to start pumping data into.\n",
    "Let's do that!\n",
    "\n",
    "These are the steps that we're following:\n",
    "1. we'll load our PDFs.\n",
    "2. the PDFs will be split into chunks, to ensure they're not too long for the model.\n",
    "3. We'll store these chunks into the database as embeddings.\n",
    "\n",
    "We're going to work with some PDFs I've included as an example:\n",
    "* A paper each from Julie Iskander, Michael Milton, and myself.\n",
    "* A report from 2022 about the Bioinformatics training needs in Australia.\n",
    "* The monopoly rulebook\n",
    "The point being to see how well the LLM+RAG works with varied types of documents\n",
    "\n",
    "After we've put the data in there, we'll try querying it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "636853de-6be7-4125-a5c1-cd5301fc847e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "# Let's start adding documents!\n",
    "# We'll be using the PyPDFLoader utility from langchain\n",
    "from langchain_community.document_loaders.pdf import PyPDFLoader\n",
    "import glob\n",
    "\n",
    "# this traverses the \"data\" folder, looking for pdfs and then loading them\n",
    "loaded_docs = [PyPDFLoader(doc).load() for doc in glob.glob(\"data/*.pdf\")]\n",
    "print(len(loaded_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0412f576-aaf5-4074-a042-af025b5abde3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'data/1-s2.0-S0266352X20300379-main-1.pdf', 'page': 0}, page_content='Contents lists available at ScienceDirect\\nComputers and Geotechnics\\njournal homepage: www.elsevier.com/locate/compgeo\\nResearch Paper\\nAscalableparallelcomputingSPHframeworkforpredictionsofgeophysical\\ngranular flows\\nEdward Yanga,b, Ha H. Buia,b,⁎, Hans De Sterckd, Giang D. Nguyenc, Abdelmalek Bouazzab\\naMonashComputationalGeomechanics(MCG)Lab,MonashUniversity,Australia\\nbDepartmentofCivilEngineering,MonashUniversity,Australia\\ncSchoolofCivil,Environmental&MiningEngineering,UniversityofAdelaide,Australia\\ndDepartmentofAppliedMathematics,UniversityofWaterloo,Canada\\nARTICLE INFO\\nKeywords:\\nParallel computing\\nMessage Passing Interface (MPI)\\nSmoothed Particle Hydrodynamics (SPH)\\nGranular flowsGeophysical flowsABSTRACT\\nThis paper presents a parallel computing Smoothed Particle Hydrodynamics (SPH) framework for geophysical\\ngranular flows scalable on large CPU clusters. The framework is accomplished by adopting a Message PassingInterface (MPI) approach with domain partitioning strategy. The Orthogonal Recursive Bisection (ORB) tech-\\nnique is utilised to subdivide the computational domain. The ORB algorithm is implemented such that any\\nnumberofMPIprocessescanbeusedinsteadofbeinglimitedtopowersoftwo.Toavoidglobalcommunicationsintheparticledistributionprocess,adiffusion-baseddistributionalgorithmisimplementedanddemonstratedto\\nbe much faster than global communication approaches when distributing particles to non-neighbouring pro-\\ncesses. The proposed parallel scheme achieves 95% weak scaling efficiency and up to 900 times strong scalingspeedupon1024CPUcores.Theparallelschemeenablespreviouslyunfeasiblesimulationstobecarriedoutand\\nhere we apply it to the investigation of the granular column collapse experiment under full three-dimensional,\\naxisymmetric conditions for aspect ratios up to 30, not attempted previously using numerical techniques in theliterature. Enabled by the parallel scheme, the simulations use up to 11.7 million SPH particles. The in-vestigation is conducted using two popular constitutive models commonly used in modelling of granular flows:\\nthe elasto-plastic model with Drucker-Prager yield criterion and the\\nµ I( )\\nrheological model. While very good\\nagreement with experimental data has been reported for both models for small and intermediate aspect ratios,\\nthe large-scale simulations conducted for large aspect ratios show that the Drucker-Prager model tends to over-\\npredict final deposit height, and the\\nµ I( ) model under-predicts it. Furthermore, due to the capability of the\\nparallel scheme to model the 3D axisymmetric column collapse at higher resolutions, we demonstrate that the\\nelasto-plastic approach is capable of capturing arching effects in the stress profile, whereas the\\nµ I( ) model\\ncannot.\\n1. Introduction\\nGeophysical granular flows are of importance to geotechnical en-\\ngineers due to the hazard of post-failure flows that can affect commu-\\nnitiesaroundtheworld.The2008Wenchuanearthquakethattriggered\\nthousands of landslides in Sichuan, China, which resulted in almost\\n20,000deathsintheregionisanexampleofsuchhazards [1].Another\\nexample is the persistent high-frequency landslide events in NewZealand,whichleadtoanestimatedannualcostofNZ$250–300million\\nindirectcostsinadditiontoindirectcostslikeroadclosuresandlossof\\nproductivity [2]. Because these types of post-failure events are large in\\nscale, it is important to developnumerical tools that are capable of notonly capturing the physics of failure flows related to these events, butalso possessing computational power to do so.\\nNumerical modelling tools used in conjunction with traditional\\ntechniques have been popular in the study or prediction of flow beha-viours to reduce damages or loss of life as a consequence of landslide\\nevents[3,4]. However, the computational cost of modelling Geophy-\\nsical granular flows in three dimensions is very high. One choice to\\novercome this issue, is to model the problem in two spatial dimensions\\nrather than three [4–11]. However, this can result in unrealistic pre-\\ndicted behaviour [12]. Another choice is to drastically reduce compu-\\ntation times by introducing parallel computing capabilities, thus en-\\nablingresearcherstoconductfull3Dsimulationsofmorecommonplace\\ngranular flows in geotechnical engineering using either mesh-based or\\nmesh-lessmethods.Acommonlyusedexampleofamesh-basedmethod\\nhttps://doi.org/10.1016/j.compgeo.2020.103474\\nReceived 6 September 2019; Received in revised form 10 November 2019; Accepted 29 January 2020⁎Corresponding author at: Department of Civil Engineering, Monash University, Australia.\\nE-mailaddress: Ha.Bui@monash.edu (H.H. Bui).Computers and Geotechnics 121 (2020) 103474\\nAvailable online 29 February 2020\\n0266-352X/ © 2020 Elsevier Ltd. All rights reserved.\\nT'), Document(metadata={'source': 'data/1-s2.0-S0266352X20300379-main-1.pdf', 'page': 1}, page_content='in geotechnical engineering is the Finite Element Method (FEM).\\nHowever, geological flows present a challenge to traditionalFEM since\\nlarge deformations can lead to severe mesh distortions which require\\nthe application of adaptive re-meshing techniques. Particle-based\\nmethodsaimtoaddresstheshortcomingsofmesh-basedmethodsinthe\\ncontext of large deformation applications by using material points to\\nstore material information and using a background mesh to solve for\\nthe motion of the material. Prime examples of these methods are the\\nMaterial Point method (MPM) and Particle Finite Method (PFM)\\n[13–15]. The advantage of such methods are that they can overcome\\nmesh-distortion issues that can occur in mesh-based methods, while\\nretaining other useful features of mesh-based methods. These methods\\nhavebeenappliedextensivelytogeotechnicalengineeringandgranular\\nflow applications [16–18].\\nMesh-less methods, as the name suggests, do not rely on a mesh to\\nperformcomputations andarefreeofchallengesassociatedwithmesh-\\nbased methods. Of the mesh-less numerical methods, the Discrete\\nElement Method (DEM) is popular because it models material as dis-\\ncreteparticlesandthensolvesforthemotionofparticlesusingparticle\\ninteraction forces relying on fewer constitutive behavioural assump-\\ntions[19–22]. However, DEM is a comparatively computationally ex-\\npensivenumericalmethodandusingDEMtomodelrunouteventswith\\nsufficiently realistic particle diameters, even with the introduction of\\nparallelism on large-scale computing systems, is not practicable to the\\nbestofourknowledge.Inthissense,atrulycontinuum-basedmesh-less\\nmethod has clear advantages in terms of computational efficiency and\\ncan help overcome the above mentioned issues if enhanced with par-\\nallel algorithms. The Smoothed Particle Hydrodynamics (SPH) numer-\\nicalmethodhasdemonstratedgreatpotentialinnotonlysimulationsof\\ngranular flows [11,23–28], but a wide range of other applications in\\ngeomechanics [22,29–31] and will be used as a basis for further de-\\nvelopment in this study.\\nSPH discretises a problem domain into a set of particles and allows\\nfor the determination of field quantities using a kernel approximationbased on statistical interpolation techniques. These field quantity ap-\\nproximations canthen beused to solvefor theLagrangian motionof the\\nparticles.Themethodwasoriginallyappliedtoastrophysicalsimulations\\n[32,33]and found application in computational fluid dynamics [34].\\nSPH was also found capable of modelling solids [35]and granular ma-\\nterials[23]. SPH has been shown to be useful in related aspects of geo-\\ntechnical modelling such as slope failure [36–38], soil-water coupling\\n[29,39], and soil-structure interaction [24,25,28]. The versatility and\\nsuitability of SPH in geological hazard modelling can be demonstrated\\nfurther by existing applications such as work done in [10]which uses\\ndepth-integrated equations to model saturated debris flow. Examples of\\nfull-3D modelling of geological hazards include application to lava flow\\nmodelling including thermal coupling and solidification behaviour [8].\\nSPHhasalsobeenshowntobecompatiblewithvisco-plasticconstitutivemodels, representative of the fluid regime of granular material\\n[26,40,41].ThekeyadvantagesofSPHovertraditionaltechniquesisthe\\nabsence of any underlying mesh, its relative computational inexpen-\\nsiveness, and versatility in being able to include various constitutive\\nbehaviours.However,aserialSPHcode,despiterelativeinexpensiveness\\nof the method, can only model flows at very low resolutions in practical\\ntime-frames, therefore introducing resolution based approximation error\\nas well as sacrificing the influence of surface detail on geological flow\\nbehaviour.Therefore,parallelcomputingisrequiredsuchthatgeological\\nflows can be modelled at sufficient resolution.\\nWhile in the literature parallelism has already been introduced to\\ngeomaterial applications of SPH, existing schemes rely on single com-\\npute node approaches such as single Graphics Processing Units (GPUs)\\napproaches or shared memory schemes such as OpenMP [42,43]. Cur-\\nrently, single high-end GPUs are capable of simulating ten or more\\nmillionsofSPHparticles.However,whensimulatingincreasinglylarger\\nproblems, single compute nodes eventually become constrained by\\navailablememoryand/orcomputepower.Oneavenuetoovercomethischallenge, is to employ distributed-memory parallelism using the\\nMessagePassingInterface(MPI)communicationstandard,allowingfor\\ncomputations to be conducted in parallel on multiple compute nodes,\\nthereforeintroducingmorememoryandcomputationalpower.MPIcan\\nbe utilized either on its own or hybridised with OpenMP [44], or in\\nmulti-GPU approaches that use MPI to transfer information betweencompute nodes [45]. In this paper, we develop a pure scalable MPI\\nframework implementation on CPU clusters. Many modern super-computers feature powerful CPU nodes with high-end GPU back-ends\\noneachnode.TheseGPUback-endsareanattractiveoptionforfurther\\nspeeding up the SPH code, and we defer extension of the MPI-based\\ncode to using GPU back-ends to future work. The most common ap-\\nproach to parallelising classical SPH on distributed memory computers\\nistoseparatetheproblemdomainintodistinctsubdomainsandallocate\\na subdomain and the contained particles in it to a compute core and\\nassociated MPI process. Halo layers of particles are then distributed\\nbetween subdomains in each time-step so that field variables of parti-\\ncles contained within each subdomain can be computed in parallel.\\nBecauseofthecomputationaloverheadandcommunicationsassociated\\nwith distributing halo layers, it is generally desirable for the geometry\\nofsubdomainstobesuchthattheinterfacialsurfaceareabetweenthem\\nis minimised and does not grow for increased problem sizes or number\\nof subdomains.\\nFrom alarge-scale numerical modelling viewpoint, the axisymmetric\\ngranular column collapse experiment is a challenge, for which a paral-\\nlelised numerical tool is needed. The experiment itselfis a granularflow\\nproblem that can be related to the physics of gravity-driven geological\\nhazards such as landsides, or to a cliff-face collapse and subsequent\\nspreading of material over a horizontal surface [46,47]. While this ex-\\nperiment has been studied through numerical means, numerical model-lingisoftenrestrictedtothetwo-dimensionalcaseduetocomputational\\ncost. And when the three-dimensional axisymmetric version of the ex-\\nperiment is modelled, only small to intermediate aspect ratios can bemodelled for the same reason [28,47–50]. A shortcoming of being re-\\nstrictedtotwo-dimensionalstudiesisthatthespreadingbehaviourofthe\\nthree-dimensional axisymmetric case is different when compared to the\\n2Dcase,andwhenconsideringrealisticgeophysicalgranularflows,they\\ndo not often flow under channelized or quasi-two-dimensional condi-\\ntions,andtypicallyspreadingoccursinmanydirections.Furthermore,at\\nlarge aspect ratios,thecollapseof thegranularcolumn exhibits complex\\nbehaviours that can be difficult to characterise using analytical ap-\\nproaches and could have potential implications for hazard prediction.\\nWhile large aspect ratios can be modelled by coarsening the spatial\\ndiscretisation, a small ratio of problem size to Representative Volume\\nElement (RVE) size (i.e. an SPH particle) may significantly reduce the\\naccuracy. Furthermore, it can introduce error when predicting runout\\ndistances, as well as sacrificing important detail in the kinematics, such\\nas small free-surface waves, and interfaces between quasi-static de-\\nposited material and dynamic flowing material [51].\\nIn this paper, we present a parallelised SPH scheme targeting for\\nscalability on large-scale compute clusters with more than 1,000 CPU\\ncoresaswellasthefirstapplicationofsuchaschemetogranularflows.\\nThe scheme uses the Orthogonal Recursive Bisection (ORB) domain\\npartitioningtechniqueforshort-rangeinteractionparticlemethodssuch\\nasin[44,52],whichisenhancedinseveralways.TheORBtechniqueis\\nchosen as it offers a good trade-off in terms of simplicity and mini-\\nmization of interfacial surface area between process subdomains,\\ntherefore facilitating scalability in the overall parallel scheme. Ad-\\nditionally, scalability is achieved by maintaining particle information\\nexchange between neighbours only. To reduce global communications,\\na diffusion-based algorithm is introduced for distributing particle in-\\nformation between non-neighbouring processes [53]. While a similar\\nORB-basedparallelschemehasbeenintroducedforwaterflowsinSPH\\nin[44],thispaperappliestheschemetogranularflows,withtwomore\\ncomplexconstitutivemodelsrepresentativeofgranularflowscombined\\nwithSPH.Thefirstmodelisthe\\nµ I( )\\nrheologicalmodel [54],apopularE.Yang,etal. Computers and Geotechnics 121 (2020) 103474\\n2'), Document(metadata={'source': 'data/1-s2.0-S0266352X20300379-main-1.pdf', 'page': 2}, page_content='exampleofthevisco-plasticfluidapproachofmodellinggranularflows,\\nand the second model is the Drucker-Prager elastic-perfectly plastic\\nmodel presented by Bui et al. [23]which is a popular example of an\\nelasto-plastic approach to granular flows in SPH. The following threereasons motivate the work presented in this paper. First, while both\\napproaches have been used in the literature [41,55–57], neither have\\nbeenparallelisedforlarge-scalecomputeclusters.Second,despitetheir\\npopularity, adirectcomparison hasnot been madebetween them.And\\nfinally, while both models have been applied to the granular column\\ncollapseexperiment,simulationshaveyettobeconductedforveryhigh\\naspect ratios under axisymmetric conditions. We present the paralleli-\\nsation of both models to demonstrate the general applicability of the\\nparallel scheme to granular flows modelled by SPH. From here on, the\\ncodevariantthatusesthe\\nµ I( )\\nmodel[54]willbereferredtoasthe\\nµ I( )\\nvariant,andthecodevariantthatusestheDrucker-Pragermodelwillbereferred to as the DP variant.\\n2. Numerical scheme\\n2.1. Governingequations\\nIn continuum mechanics, the mass and momentum conservation\\nequations are the governing equations describing the motion of a ma-\\nterial. These can be applied to model granular flows and are given as:\\n=D\\nDtv\\nx1,\\n(1)\\n= +Dv\\nDt xf1,\\n(2)\\nwhere Einstein summation is used for repeated indices;\\n and\\ncorre-\\nspondtotheCartesian\\nx ,\\ny,\\nzcoordinates;\\n isthematerialdensity;\\nv is\\nthe velocity;\\nx is the Cartesian position; and\\n corresponds to the\\nCauchy stress tensor.\\nToclosetheabovegoverningequations,aformulationforthestress\\ntensor is required. The traditional approach to formulating the stress\\ntensor is as follows:\\n= + P ,\\n(3)\\nwhere\\nPisanisotropicpressure;\\n istheshearstresstensorand\\n is\\nKronecker’s delta. In this paper, we adopt two different approaches to\\nidentifythestresstensor:the\\nµ I( ) rheologyasdescribedin [54]andthe\\nDrucker-Prager elastic-perfectly plastic model as implemented in SPH\\nin[23]. This section will briefly outline each model.\\n2.2. Constitutivemodels\\nTo formulate the stress tensor for granular flows, numerical mod-\\nelling practitioners generally adopt either a visco-plastic or elasto-\\nplasticapproach.Forthevisco-plasticapproach,weimplementthe\\nµ I( )\\nmodel[54], which can be thought of as an extension of the Bingham\\nfluid model with pressure and friction dependent yield stress for ap-\\nplicationtodensegranularflows.Asfortheelasto-plasticapproach,the\\napproach presented in [23]is adopted herein. This section will first\\ndescribe the model and then the elasto-plastic approach.\\n2.2.1.\\nµ I( )rheologicalconstitutivemodel\\nThe\\nµ I( ) rheological model was developed to capture the inertial\\neffects of granular material in the dense regime. It models the granularmaterial as a visco-plastic fluid, with a Drucker-Prager like yielding\\ncondition. When the stress state of the material is beneath the yielding\\nstress, the material does not flow. Above the yielding stress, the ma-\\nterialflowslikeanon-Newtonianfluid.Toformulatethestresstensorin\\nEq.(3), the implementation of the\\nµ I( )\\nmodel adopts the following\\nequation of state to represent the isotropic pressure:\\n=P c ( ), i i2\\n0(4)\\nwhere\\ncisthespeedofsound,\\ni isthedensityofparticle\\ni ,and\\n0isthe\\nreference density of the material. The shear stress tensor is determined\\nby,\\n=2 ,\\n(5)\\n=µP,\\n(6)\\n= ++µ µµ µ\\nI I/ 1,sp s\\ni0\\n(7)\\nwhere\\nisanapparentviscosity;\\nµ isafrictionalfunctiondependenton\\ntheinertialnumber,\\n=Iid\\nP/i i\\ni0 ;\\n= +( )iv\\nxv\\nxi1\\n2 isthestrainrate;\\nd\\nistherealgraindiameter;and\\nµs ,\\nµp,and\\nI0areconstants.Themodel\\nincludes a Drucker Prager-like yield criterion such that no flow occurs\\nwhen\\nµ Ps1\\n2 [54]. To avoid undesirable or undefined beha-\\nviours, the shear component of the stress tensor is assumed to equal 0\\nwhenthepressureisnegative,andthestrainratetensorisinitializedas\\n107\\nas zero strain rates can result in mathematically undefined beha-\\nviour. It is also worth noting that the apparent viscosity does not re-quire other regularizations that are typically implemented in non-\\nNewtonian fluid models. This is because despite the local viscosity,\\n,\\ndiverging for a vanishing strain-rate, the shear stress is bounded by\\n=µ P µ P[ , ] 0s p1\\n2\\n.\\n2.2.2. Drucker-Pragerelastic-perfectlyplasticconstitutivemodel\\nWhilethevisco-plasticapproachofmodellinggranularflowsderive\\nthe stress tensor from instantaneous density and strain-rate, the elasto-plastic approach instead evolves the stress tensor over time using a\\nstress-strain relationship that relates the stress-increment to the strain-\\nincrement. Plasticity theory dictates that for an elasto-plastic material,\\nthe total strain-rate tensor is decomposed into elastic,\\ne\\n, and plastic\\ncomponents,\\np :\\n= + ,e p\\n(8)\\nwhere the elastic part is determined by the generalized Hooke’s Law:\\n= +s\\nGv\\nE 21 2\\n3,e\\n(9)\\nwhere\\ns isthedeviatoricshearstress-ratetensor,\\nE and\\nGareYoung’s\\nand shear modulus respectively, and\\nv is Poisson’s ratio.\\nTheplasticcomponentofthestrain-ratetensorcanbedefinedusing\\nthe plastic flow rule:\\n=g,p\\n(10)\\nwhere\\nistherateofthechangeoftheplastic-multiplier,\\n ;and\\ngisthe\\nplastic potential function. Plastic deformation only occurs when theyield criterion is satisfied where the Drucker-Prager criterion is\\nadopted:\\n= + = f I J I J k ( , ) 0, c 1 2 1 2\\n(11)\\nwhere\\nI1and\\nJ2arethefirstandsecondinvariantsofthestresstensor;\\nand\\nkcare Drucker-Prager constants related to the Coulomb internal\\nfriction angle (\\n ) and cohesion (\\nc ) respectively;\\n and\\nkcare respec-\\ntively calculated in three dimensions as:\\n=2sin\\n3 (3 sin ),\\n(12)\\n=×kc6 cos\\n3 (3 sin ), c\\n(13)\\nThenon-associatedplasticflowruleisusedtodefinetheplasticflow\\nrule:E.Yang,etal. Computers and Geotechnics 121 (2020) 103474\\n3')]\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "# This is the chunking step. We'll be splitting the text into\n",
    "# 1000-character chunks with 40 character overlap.\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=40,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "split_docs = []\n",
    "for doc in loaded_docs:\n",
    "    split_docs.extend(doc)\n",
    "print(split_docs[:3])\n",
    "print(len(split_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a5b8a49-0c62-46b1-88de-40a7a49ecfd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['d2940d2b-eee9-4090-ab9b-c67ccc1689fb',\n",
       " '92438ca6-cd89-4970-85be-a8046e697045',\n",
       " 'ca62cf2e-3691-485b-971a-ca6e613eedae',\n",
       " '5dd22d95-3cd0-4739-a7e8-7f4d637d0bc9',\n",
       " 'df13f8c4-06ad-41d1-8cb4-4d3e63ceabf3',\n",
       " '76670f1b-75fa-40e2-9760-974f5463657d',\n",
       " '83993c0b-d468-4a99-8572-901616cad99b',\n",
       " '8bc17623-a5a4-4a28-b84a-74787b8dc1e1',\n",
       " '37073fe3-3061-49dc-a474-a7d30c15fd1b',\n",
       " '8e608fb2-42df-4c60-9f16-362afb03e283',\n",
       " '34ce1735-3d9d-4a64-98bb-338d773eb72b',\n",
       " '016c1964-1b91-4c2c-afac-05b563fe5256',\n",
       " '08855da0-2076-406c-b21d-251dd9448acc',\n",
       " '8a4d9730-341c-4cc2-8722-99dd5ce06344',\n",
       " '99e98cff-74af-4f4b-abbb-4c544b23144b',\n",
       " '92bcbb0d-b900-48f8-ac8b-fddca7f53b97',\n",
       " '6ad6c784-73ac-4990-9e02-fc5ad1f37837',\n",
       " 'bb81db11-0bf5-468c-a7e4-abbe5ef19964',\n",
       " 'd9985098-d35b-41c3-886a-8ac6c097cd01',\n",
       " 'd6391404-2047-4a2f-8257-66782bac1ca8',\n",
       " '64ced2a4-bec7-4fa9-a5a7-e8e687897041',\n",
       " '860afc82-86a0-4c90-bcc9-625f5345d15f',\n",
       " '92630e2a-b8d1-435c-b545-a5283fbe3452',\n",
       " '1d9a95f4-422f-42d6-abf0-7c28ad644570',\n",
       " 'e91606a4-b9d5-4225-817c-c018ec6eb51b',\n",
       " 'a5ea92f8-c6aa-4ba4-af8f-116812223959',\n",
       " 'e10ffdd0-57b4-428c-a4bd-fc7b95f434f0',\n",
       " '588a510e-5ac5-481f-a29d-31fbd34e1af4',\n",
       " '5a8c8d93-e1cd-4d36-bf0d-e61ba2dd8cda',\n",
       " 'd14d956d-0892-404a-b8c2-d21e79fc964d',\n",
       " 'e1590206-5859-4aec-8dd5-0f00ce787db1',\n",
       " '51a4d1b7-a8dd-4f5e-8852-66ec7e2168c8',\n",
       " '67b08052-bb36-4427-8302-9282b9062297',\n",
       " '9119c203-1129-4a46-bfe2-858a8f0e88d8',\n",
       " 'd65db42e-7113-435e-9bcd-c428037a7587',\n",
       " 'f340d623-4637-477f-9be4-04e2e80bca35',\n",
       " '3f429d82-7f71-4c32-9434-b51dce703958',\n",
       " 'db5393d6-892a-4cbb-836b-c6ada55b8cef',\n",
       " '663ecea7-5c5b-4404-a1fb-40a087d7237a',\n",
       " 'f7ac3bde-726e-4740-9e3a-2d8f0677118c',\n",
       " 'af2ace95-b204-45b8-9866-a44ac28ada37',\n",
       " 'cca29b9c-3c39-4a02-95e6-e79ef909a420',\n",
       " '563001ad-bdb6-4270-83d8-33d2b811b41f',\n",
       " 'dbf47f44-49be-4455-bc3a-6cadc38b0905',\n",
       " '6387d336-8f92-4f16-9a8a-9f6b4baa9f8a',\n",
       " 'f04beaaa-62b8-4668-88db-bd0c6d6f530f',\n",
       " '4b882be7-f26d-471f-a654-0d90355887a3',\n",
       " '64122d27-3f9e-45c8-b1b8-fd60ceb4eea8',\n",
       " 'bc7a2b7f-1884-4a1a-8ed3-d6279774fd4c',\n",
       " '386df626-636d-4b42-a640-fad8f8b25df3',\n",
       " '995910e3-f5b4-4763-bba3-780b4ac22667',\n",
       " '42151895-d735-435f-ae9d-303310f73b46',\n",
       " 'b10c5260-6dbd-4ca9-95af-c7784019fbfd',\n",
       " '3207d192-c96f-4e6f-b44c-58cd315dacfc',\n",
       " '3ea9d6c8-e284-4ec5-9ea9-d93e437635b0',\n",
       " '729851a7-3a67-4bd0-af6e-ec4d9ce070c8',\n",
       " '27ad19a3-adeb-4c3f-aa72-c169cb1477ce',\n",
       " 'f7db354d-903e-411c-a701-29f522029b7b',\n",
       " 'b4179243-7615-4589-9336-b75f238e83ce',\n",
       " '816cbdf4-c8b4-480d-926d-3a9bff8f64b9']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, we cna add our split chunks into the database\n",
    "db.add_documents(split_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a0ea17-1679-46cc-a2ff-d0191ad41917",
   "metadata": {},
   "source": [
    "# Querying the database\n",
    "\n",
    "Now that the documents are embedded and stuffed into the database,\n",
    "we can begin querying it. Langchain's Chroma interface provides two\n",
    "convenient functions to query the database with:\n",
    "* `max_marginal_relevance_search`\n",
    "    * This tries to get chunks that have less overlap in content, maximising the \"marginal relevance\" of each chunk\n",
    "* `similarity_search_with_relevance_score`\n",
    "    * Tries to get the chunks that are most relevant (according some internal metric)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b22f76f-0fb2-44b8-83b1-643564ca4ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what are the bioinformatics training needs in Australia?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a86bbb5c-31c2-4de6-bb8c-fa33965a62eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document: data/1_Australian_bioinformatics_training_needs_survey_2021_22_Report.pdf, page: 0\n",
      "\n",
      "Content:\n",
      "Bioinformatics training needs of Australianresearchers: 2021/22 surveyMelissa L. Burke1,2,3Ann Backhaus4, Mariana Barnes5,Michael Charleston6, Tyrone Chen7,8,Tracy Chew9,  Jeffrey H. Christiansen1,2,3, Mark Crowe3,Deanna Deveson10, VictoriaPerreau11, Jingbo Wang12, Nathan Watson-Haigh13, ChristinaR. Hall1,111. Australian BioCommons, Australia, 2. Research Computing Centre, The University ofQueensland, Queensland, Australia, 3. Queensland Cyber Infrastructure Foundation,Queensland, Australia. 4. Pawsey Supercomputing Research Centre, Western Australia,Australia, 5. Menzies School of Health Research, Darwin, Northern Territory, Australia, 6.University of Tasmania, Tasmania, Australia, 7. COMBINE - Australian ComputationalBiology and Bioinformatics Student Society, Australia, 8. Monash University, Victoria,Australia, 9. Sydney Informatics Hub, University of Sydney, New South Wales, Australia, 10.Monash Bioinformatics Platform, Biomedicine Discovery Institute, Faculty of Medicine,Nursing and Health Sciences, Monash University, Victoria, Australia, 11. MelbourneBioinformatics, University of Melbourne, Victoria, Australia, 12. National ComputationalInfrastructure,Australian National University,AustralianCapital Territory, Australia, 13. SouthAustralian Genomics Centre, South Australia, Australia.On behalf of the National Bioinformatics Training Cooperative.\n",
      "\n",
      "\n",
      "Document: data/1_Australian_bioinformatics_training_needs_survey_2021_22_Report.pdf, page: 2\n",
      "\n",
      "Content:\n",
      "IntroductionBioinformatics has become a core part of life science research. Life scientists mustcontinually gain and refresh their bioinformatics skills in order to take advantage of newtechnologies, move between research topics and progress their careers.To ensure training remains relevant, life science trainers must keep pace with the rapidlydeveloping field and evolve their training offerings to respond to demand and changes inscientific thinking.In 2016 EMBL-ABR (a precursor of Australian BioCommons) surveyed life scientists andmedical researchers to gauge bioinformatics and computational biology needs in Australia.More than 90% of respondents considered training to be important, with demand forimmediate training on all suggested topics: basic computing (Linux) and scripting (Python,R);data management and metadata; integrating multiple data types; and scaling analysis tocloud1. Similar results were obtained from surveysin European and US settings2.Much has changed in the world of bioinformatics since 2016. New technologies andmethodologies have been developed (e.g. scRNAseq) and certain tools and platforms havebecome more accessible and popular among life scientists (e.g Galaxy, RStudio). Thepandemic has also changed the way that we work and collaborate. Given these changes, are-evaluation of training needs and preferred modes of learning was necessary.Here we summarise the results of the 2021/22 Australian Bioinformatics Training NeedsSurvey.Survey design and roll outThe survey was developed by theNational BioinformaticsTraining Cooperativeconvened byAustralian BioCommons. It is modelled on a 2020 survey of the Melbourne BiomedicalPrecinct conducted by the Parkville Bioinformatics Training Group (personal communicationDr Victoria Perreau, Melbourne Bioinformatics). The questions included in our survey areprovided as a supplementary file.The survey was designed to address four key questions:●What training do people already access?●Are their training needs being met?●What format of training is preferred?●What topics need to be covered?\n",
      "2\n",
      "\n",
      "\n",
      "Document: data/1_Australian_bioinformatics_training_needs_survey_2021_22_Report.pdf, page: 16\n",
      "\n",
      "Content:\n",
      "Supplementary files in this Zenodo record-Questions asked in the survey (PDF):Australian_bioinformatics_training_needs_survey 2021_2022 .pdf-Anonymised responses to the survey (names and email address have beenredacted):Australian_bioinformatics_training_needs_survey_2021_2022_anon_results.csvReferences1.Schneider, M. V., Flannery, M. & Griffin, P. Survey of Bioinformatics and ComputationalNeeds in Australia 2016.pdf. (2016) doi:10.6084/m9.figshare.4307768.v1.2.Attwood, T. K., Blackford, S., Brazas, M. D., Davies, A. & Schneider, M. V. A globalperspective on evolving bioinformatics and data science training needs.Brief. Bioinform.20, 398–404 (2017).3.Lonie, A. J. What is the Australian BioCommons?4.Hall, C. R., Griffin, P. C., Lonie, A. J. & Christiansen, J. H. Application of a bioinformaticstraining delivery method for reaching dispersed and distant trainees.PLOS Comput. Biol.17, e1008715 (2021).5.Unsworth, Kathrynet al.DReSA: Project team reflections.(2021)doi:10.5281/ZENODO.5712128.6.Beard, N.et al.TeSS: a platform for discoveringlife-science training opportunities.Bioinformatics36, 3290–3291 (2020).\n",
      "16\n",
      "\n",
      "\n",
      "Document: data/1_Australian_bioinformatics_training_needs_survey_2021_22_Report.pdf, page: 10\n",
      "\n",
      "Content:\n",
      "A small proportion (14 respondents, 11%) responded ‘None’, ‘Nil’ or ‘NA’ to this questionsuggesting that they are unaware of or have not accessed training by any of the providerslisted. Additionally, more than two thirds of respondents were not sure, or felt that theirtraining needs would not be met by their local institutions (Figure 6). Together with anecdotalreports from training providers that life scientists are unaware of sources of training, thissuggests that awareness of national bioinformatics training opportunities could be improved.\n",
      "Figure 6: Confidence that training needs will be met by local institutions.\n",
      "10\n",
      "\n",
      "\n",
      "Document: data/1_Australian_bioinformatics_training_needs_survey_2021_22_Report.pdf, page: 13\n",
      "\n",
      "Content:\n",
      "Figure 10: Desired training by topic.Respondentscould select multiple options.\n",
      "13\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Trying `max_marginal_relevance_search`, with 4 results\n",
    "search_res = db.max_marginal_relevance_search(\n",
    "    question, \n",
    "    k=5\n",
    ")\n",
    "\n",
    "# printing the documents with some info.\n",
    "for res in search_res:\n",
    "    print(f\"Document: {res.metadata['source']}, page: {res.metadata['page']}\\n\")\n",
    "    print(f\"Content:\\n{res.page_content}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7e26bae-a3a6-4a54-a766-3073a77fac79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document: data/1_Australian_bioinformatics_training_needs_survey_2021_22_Report.pdf, page: 0\n",
      "Relevance score [0, 1]: 0.8085996971129107\n",
      "\n",
      "Content:\n",
      "Bioinformatics training needs of Australianresearchers: 2021/22 surveyMelissa L. Burke1,2,3Ann Backhaus4, Mariana Barnes5,Michael Charleston6, Tyrone Chen7,8,Tracy Chew9,  Jeffrey H. Christiansen1,2,3, Mark Crowe3,Deanna Deveson10, VictoriaPerreau11, Jingbo Wang12, Nathan Watson-Haigh13, ChristinaR. Hall1,111. Australian BioCommons, Australia, 2. Research Computing Centre, The University ofQueensland, Queensland, Australia, 3. Queensland Cyber Infrastructure Foundation,Queensland, Australia. 4. Pawsey Supercomputing Research Centre, Western Australia,Australia, 5. Menzies School of Health Research, Darwin, Northern Territory, Australia, 6.University of Tasmania, Tasmania, Australia, 7. COMBINE - Australian ComputationalBiology and Bioinformatics Student Society, Australia, 8. Monash University, Victoria,Australia, 9. Sydney Informatics Hub, University of Sydney, New South Wales, Australia, 10.Monash Bioinformatics Platform, Biomedicine Discovery Institute, Faculty of Medicine,Nursing and Health Sciences, Monash University, Victoria, Australia, 11. MelbourneBioinformatics, University of Melbourne, Victoria, Australia, 12. National ComputationalInfrastructure,Australian National University,AustralianCapital Territory, Australia, 13. SouthAustralian Genomics Centre, South Australia, Australia.On behalf of the National Bioinformatics Training Cooperative.\n",
      "\n",
      "\n",
      "Document: data/1_Australian_bioinformatics_training_needs_survey_2021_22_Report.pdf, page: 14\n",
      "Relevance score [0, 1]: 0.8074853820129444\n",
      "\n",
      "Content:\n",
      "Figure 10: Desired training by skill.Respondentscould select multiple options.Next stepsThere are an estimated 30,000 life science researchers in Australia3. The results of thissurvey offer a glimpse of the bioinformatics training needs of a small subset of this groupand provide a platform for the discussion and prioritisation of bioinformatics training inAustralia. We plan to repeat this survey on a regular basis to gauge changes in trainingneeds over time and to reach a larger subset of the life sciences community.Currently, the National Bioinformatics Training Cooperative is using the information gatheredin this survey to identify gaps in training offered, prioritise training topics and inform thedevelopment of our training program. In view of the results of the survey and current COVIDrestrictions, we continue to prioritise live online training with the intention of shifting to amixture of hybrid (as per Australian BioCommons’previouslypublished model4) and fullyonline events in the future.The survey indicated that there is some need to raise awareness of existing bioinformaticstraining in Australia. As a first step to address this we have compiled a list ofAustralianbioinformatics training providersand made this publiclyavailable. The AustralianBioCommons is also actively involved in promoting the use of training registries such asDReSA5andELIXIR’s TeSS6to improve findabilityof digital skills and bioinformatics14\n",
      "\n",
      "\n",
      "Document: data/1_Australian_bioinformatics_training_needs_survey_2021_22_Report.pdf, page: 2\n",
      "Relevance score [0, 1]: 0.7996979052811165\n",
      "\n",
      "Content:\n",
      "IntroductionBioinformatics has become a core part of life science research. Life scientists mustcontinually gain and refresh their bioinformatics skills in order to take advantage of newtechnologies, move between research topics and progress their careers.To ensure training remains relevant, life science trainers must keep pace with the rapidlydeveloping field and evolve their training offerings to respond to demand and changes inscientific thinking.In 2016 EMBL-ABR (a precursor of Australian BioCommons) surveyed life scientists andmedical researchers to gauge bioinformatics and computational biology needs in Australia.More than 90% of respondents considered training to be important, with demand forimmediate training on all suggested topics: basic computing (Linux) and scripting (Python,R);data management and metadata; integrating multiple data types; and scaling analysis tocloud1. Similar results were obtained from surveysin European and US settings2.Much has changed in the world of bioinformatics since 2016. New technologies andmethodologies have been developed (e.g. scRNAseq) and certain tools and platforms havebecome more accessible and popular among life scientists (e.g Galaxy, RStudio). Thepandemic has also changed the way that we work and collaborate. Given these changes, are-evaluation of training needs and preferred modes of learning was necessary.Here we summarise the results of the 2021/22 Australian Bioinformatics Training NeedsSurvey.Survey design and roll outThe survey was developed by theNational BioinformaticsTraining Cooperativeconvened byAustralian BioCommons. It is modelled on a 2020 survey of the Melbourne BiomedicalPrecinct conducted by the Parkville Bioinformatics Training Group (personal communicationDr Victoria Perreau, Melbourne Bioinformatics). The questions included in our survey areprovided as a supplementary file.The survey was designed to address four key questions:●What training do people already access?●Are their training needs being met?●What format of training is preferred?●What topics need to be covered?\n",
      "2\n",
      "\n",
      "\n",
      "Document: data/1_Australian_bioinformatics_training_needs_survey_2021_22_Report.pdf, page: 15\n",
      "Relevance score [0, 1]: 0.7976014727066969\n",
      "\n",
      "Content:\n",
      "training. Australian BioCommons training events and their associated materials are listed inthese registries.SummaryThis survey provides a snapshot of bioinformatics training needs in the life sciencecommunities in Australia in late 2021.It indicates that there is continued demand for training across a wide variety of bioinformaticstopics (including omics analysis and programming languages) with new topics emergingsince the last survey was conducted in 2016 (e.g. scRNAseq and machine learning). Therehas also been a shift in attitudes concerning the format of training with online training nowmore appealing than it was in the past2.Many respondentswere unsure if their trainingneeds will be met locally. The cooperative is well placed to address this challenge of accessand visibility by enabling training to be delivered online, to a national audience regardless oflocation.The information gathered in this survey is being used by the National Bioinformatics TrainingCooperative, Australian BioCommons and partners to inform the development of our trainingprograms. Future surveys will enable us to track changes in training needs over time andrespond to shifts in demand and scientific thinking.ContributorsThis survey was developed, run and analysed by theNational Bioinformatics TrainingCooperative, convened by Australian BioCommons.LicenceThis report, the survey questions and anonymised results are provided underCreativeCommons Attribution 4.0 International (CC BY 4.0) License\n",
      "15\n",
      "\n",
      "\n",
      "Document: data/1_Australian_bioinformatics_training_needs_survey_2021_22_Report.pdf, page: 16\n",
      "Relevance score [0, 1]: 0.7128522196081266\n",
      "\n",
      "Content:\n",
      "Supplementary files in this Zenodo record-Questions asked in the survey (PDF):Australian_bioinformatics_training_needs_survey 2021_2022 .pdf-Anonymised responses to the survey (names and email address have beenredacted):Australian_bioinformatics_training_needs_survey_2021_2022_anon_results.csvReferences1.Schneider, M. V., Flannery, M. & Griffin, P. Survey of Bioinformatics and ComputationalNeeds in Australia 2016.pdf. (2016) doi:10.6084/m9.figshare.4307768.v1.2.Attwood, T. K., Blackford, S., Brazas, M. D., Davies, A. & Schneider, M. V. A globalperspective on evolving bioinformatics and data science training needs.Brief. Bioinform.20, 398–404 (2017).3.Lonie, A. J. What is the Australian BioCommons?4.Hall, C. R., Griffin, P. C., Lonie, A. J. & Christiansen, J. H. Application of a bioinformaticstraining delivery method for reaching dispersed and distant trainees.PLOS Comput. Biol.17, e1008715 (2021).5.Unsworth, Kathrynet al.DReSA: Project team reflections.(2021)doi:10.5281/ZENODO.5712128.6.Beard, N.et al.TeSS: a platform for discoveringlife-science training opportunities.Bioinformatics36, 3290–3291 (2020).\n",
      "16\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Trying `max_marginal_relevance_search`, with 4 results\n",
    "search_res = db.similarity_search_with_relevance_scores(\n",
    "    question, \n",
    "    k=5\n",
    ")\n",
    "\n",
    "# printing the documents with some info.\n",
    "for res, score in search_res:\n",
    "    print(f\"Document: {res.metadata['source']}, page: {res.metadata['page']}\")\n",
    "    print(f\"Relevance score [0, 1]: {score}\\n\")\n",
    "    print(f\"Content:\\n{res.page_content}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325d1bfa-7f20-418e-b329-b792598ad4a6",
   "metadata": {},
   "source": [
    "Whichever search type we used, the query pulled out chunks solely from the Bioinformatics training report. \n",
    "This makes sense, given none of the PDFs cover this topic (although Michael's paper covers a \n",
    "bioinformatics workflow manager). \n",
    "\n",
    "The maximal marginal relevance search did a decent job of ensuring the chunks didn't overlap in much\n",
    "in content, but ended up pulling more irrelevant chunks. It also didn't provide a score to judge how\n",
    "relevant it thought the chunk was. It might be more useful if we had more documents covering the topic\n",
    "of the question.\n",
    "\n",
    "## Summarising the retrieved chunks with an LLM\n",
    "\n",
    "Being able to get relevant chunks is already quite useful - especially if there are more than the 5\n",
    "PDFs used here.\n",
    "\n",
    "The next step is to use an LLM to summarize the information for us!\n",
    "\n",
    "The steps will be:\n",
    "* we need to integrate the retrieved documents into the prompt\n",
    "* the LLM can answer the prompt\n",
    "* we'll add the sources of information to the end of the LLMs answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9695d90d-afb8-459d-adb0-04513ad41535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bioinformatics training needs of Australianresearchers: 2021/22 surveyMelissa L. Burke1,2,3Ann Backhaus4, Mariana Barnes5,Michael Charleston6, Tyrone Chen7,8,Tracy Chew9,  Jeffrey H. Christiansen1,2,3, Mark Crowe3,Deanna Deveson10, VictoriaPerreau11, Jingbo Wang12, Nathan Watson-Haigh13, ChristinaR. Hall1,111. Australian BioCommons, Australia, 2. Research Computing Centre, The University ofQueensland, Queensland, Australia, 3. Queensland Cyber Infrastructure Foundation,Queensland, Australia. 4. Pawsey Supercomputing Research Centre, Western Australia,Australia, 5. Menzies School of Health Research, Darwin, Northern Territory, Australia, 6.University of Tasmania, Tasmania, Australia, 7. COMBINE - Australian ComputationalBiology and Bioinformatics Student Society, Australia, 8. Monash University, Victoria,Australia, 9. Sydney Informatics Hub, University of Sydney, New South Wales, Australia, 10.Monash Bioinformatics Platform, Biomedicine Discovery Institute, Faculty of Medicine,Nursing and Health Sciences, Monash University, Victoria, Australia, 11. MelbourneBioinformatics, University of Melbourne, Victoria, Australia, 12. National ComputationalInfrastructure,Australian National University,AustralianCapital Territory, Australia, 13. SouthAustralian Genomics Centre, South Australia, Australia.On behalf of the National Bioinformatics Training Cooperative.\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "Figure 10: Desired training by skill.Respondentscould select multiple options.Next stepsThere are an estimated 30,000 life science researchers in Australia3. The results of thissurvey offer a glimpse of the bioinformatics training needs of a small subset of this groupand provide a platform for the discussion and prioritisation of bioinformatics training inAustralia. We plan to repeat this survey on a regular basis to gauge changes in trainingneeds over time and to reach a larger subset of the life sciences community.Currently, the National Bioinformatics Training Cooperative is using the information gatheredin this survey to identify gaps in training offered, prioritise training topics and inform thedevelopment of our training program. In view of the results of the survey and current COVIDrestrictions, we continue to prioritise live online training with the intention of shifting to amixture of hybrid (as per Australian BioCommons’previouslypublished model4) and fullyonline events in the future.The survey indicated that there is some need to raise awareness of existing bioinformaticstraining in Australia. As a first step to address this we have compiled a list ofAustralianbioinformatics training providersand made this publiclyavailable. The AustralianBioCommons is also actively involved in promoting the use of training registries such asDReSA5andELIXIR’s TeSS6to improve findabilityof digital skills and bioinformatics14\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "IntroductionBioinformatics has become a core part of life science research. Life scientists mustcontinually gain and refresh their bioinformatics skills in order to take advantage of newtechnologies, move between research topics and progress their careers.To ensure training remains relevant, life science trainers must keep pace with the rapidlydeveloping field and evolve their training offerings to respond to demand and changes inscientific thinking.In 2016 EMBL-ABR (a precursor of Australian BioCommons) surveyed life scientists andmedical researchers to gauge bioinformatics and computational biology needs in Australia.More than 90% of respondents considered training to be important, with demand forimmediate training on all suggested topics: basic computing (Linux) and scripting (Python,R);data management and metadata; integrating multiple data types; and scaling analysis tocloud1. Similar results were obtained from surveysin European and US settings2.Much has changed in the world of bioinformatics since 2016. New technologies andmethodologies have been developed (e.g. scRNAseq) and certain tools and platforms havebecome more accessible and popular among life scientists (e.g Galaxy, RStudio). Thepandemic has also changed the way that we work and collaborate. Given these changes, are-evaluation of training needs and preferred modes of learning was necessary.Here we summarise the results of the 2021/22 Australian Bioinformatics Training NeedsSurvey.Survey design and roll outThe survey was developed by theNational BioinformaticsTraining Cooperativeconvened byAustralian BioCommons. It is modelled on a 2020 survey of the Melbourne BiomedicalPrecinct conducted by the Parkville Bioinformatics Training Group (personal communicationDr Victoria Perreau, Melbourne Bioinformatics). The questions included in our survey areprovided as a supplementary file.The survey was designed to address four key questions:●What training do people already access?●Are their training needs being met?●What format of training is preferred?●What topics need to be covered?\n",
      "2\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "training. Australian BioCommons training events and their associated materials are listed inthese registries.SummaryThis survey provides a snapshot of bioinformatics training needs in the life sciencecommunities in Australia in late 2021.It indicates that there is continued demand for training across a wide variety of bioinformaticstopics (including omics analysis and programming languages) with new topics emergingsince the last survey was conducted in 2016 (e.g. scRNAseq and machine learning). Therehas also been a shift in attitudes concerning the format of training with online training nowmore appealing than it was in the past2.Many respondentswere unsure if their trainingneeds will be met locally. The cooperative is well placed to address this challenge of accessand visibility by enabling training to be delivered online, to a national audience regardless oflocation.The information gathered in this survey is being used by the National Bioinformatics TrainingCooperative, Australian BioCommons and partners to inform the development of our trainingprograms. Future surveys will enable us to track changes in training needs over time andrespond to shifts in demand and scientific thinking.ContributorsThis survey was developed, run and analysed by theNational Bioinformatics TrainingCooperative, convened by Australian BioCommons.LicenceThis report, the survey questions and anonymised results are provided underCreativeCommons Attribution 4.0 International (CC BY 4.0) License\n",
      "15\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "Supplementary files in this Zenodo record-Questions asked in the survey (PDF):Australian_bioinformatics_training_needs_survey 2021_2022 .pdf-Anonymised responses to the survey (names and email address have beenredacted):Australian_bioinformatics_training_needs_survey_2021_2022_anon_results.csvReferences1.Schneider, M. V., Flannery, M. & Griffin, P. Survey of Bioinformatics and ComputationalNeeds in Australia 2016.pdf. (2016) doi:10.6084/m9.figshare.4307768.v1.2.Attwood, T. K., Blackford, S., Brazas, M. D., Davies, A. & Schneider, M. V. A globalperspective on evolving bioinformatics and data science training needs.Brief. Bioinform.20, 398–404 (2017).3.Lonie, A. J. What is the Australian BioCommons?4.Hall, C. R., Griffin, P. C., Lonie, A. J. & Christiansen, J. H. Application of a bioinformaticstraining delivery method for reaching dispersed and distant trainees.PLOS Comput. Biol.17, e1008715 (2021).5.Unsworth, Kathrynet al.DReSA: Project team reflections.(2021)doi:10.5281/ZENODO.5712128.6.Beard, N.et al.TeSS: a platform for discoveringlife-science training opportunities.Bioinformatics36, 3290–3291 (2020).\n",
      "16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We'll format the retrieved docs' content\n",
    "# we're joining the content by a \"---\" delimiter and a couple spaces\n",
    "formatted_docs = \"\\n\\n---\\n\\n\".join([doc.page_content for doc, _ in search_res])\n",
    "print(formatted_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e667a20d-01bd-47e8-b79f-09a497e50035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a new template\n",
    "# the variables between the curly brackets are placeholders\n",
    "# to substitute our question and chunks of content.\n",
    "template = \"\"\"Context: {context}\n",
    "\n",
    "Answer the below question, given the above context: \n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# creating a new chain\n",
    "chain = prompt | hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b93d43b5-b9d4-4fe4-94c8-ddcb77411956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The bioinformatics training needs in Australia continue to grow, as evidenced by the results of the 2021/22 Australian Bioinformatics Training Needs Survey. Respondents expressed a high level of importance for various bioinformatics training topics, including:\n",
      "\n",
      "1. Basic computing skills like Linux and scripting (Python, R)\n",
      "2. Data management and metadata\n",
      "3. Integrating multiple data types\n",
      "4. Scaling analysis to cloud environments\n",
      "\n",
      "Since the last survey in 2016, several new topics have emerged, reflecting advancements in technology and methodologies. These include:\n",
      "\n",
      "- Single-cell RNA sequencing (scRNA-seq)\n",
      "- Machine learning techniques\n",
      "\n",
      "Additionally, the pandemic has altered how life scientists work collaboratively, which may influence the type of training they seek.\n",
      "\n",
      "However, despite increased interest in bioinformatics training, many respondents still express concerns about accessing relevant training locally. This highlights the need for continuous evaluation of training needs and improved accessibility through online resources and partnerships.\n",
      "\n",
      "* Document: data/1_Australian_bioinformatics_training_needs_survey_2021_22_Report.pdf\n",
      "    * Page: 0\n",
      "    * Relevance [0, 1]: 0.8085996971129107\n",
      "* Document: data/1_Australian_bioinformatics_training_needs_survey_2021_22_Report.pdf\n",
      "    * Page: 14\n",
      "    * Relevance [0, 1]: 0.8074853820129444\n",
      "* Document: data/1_Australian_bioinformatics_training_needs_survey_2021_22_Report.pdf\n",
      "    * Page: 2\n",
      "    * Relevance [0, 1]: 0.7996979052811165\n",
      "* Document: data/1_Australian_bioinformatics_training_needs_survey_2021_22_Report.pdf\n",
      "    * Page: 15\n",
      "    * Relevance [0, 1]: 0.7976014727066969\n",
      "* Document: data/1_Australian_bioinformatics_training_needs_survey_2021_22_Report.pdf\n",
      "    * Page: 16\n",
      "    * Relevance [0, 1]: 0.7128522196081266\n",
      "\n"
     ]
    }
   ],
   "source": [
    "answer = chain.invoke({\"question\": question, \"context\": formatted_docs})\n",
    "\n",
    "# append the source documents and scores to the end of the response\n",
    "answer += '\\n\\n'\n",
    "for doc, score in search_res:\n",
    "    answer += f'* Document: {doc.metadata[\"source\"]}\\n    * Page: {doc.metadata[\"page\"]}\\n    * Relevance [0, 1]: {score}\\n'\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36281ccd-1605-4142-8dc1-ff380747612a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the db contents\n",
    "db.delete_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd86629-3186-43c5-a8db-8b7b86f4cecb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (rag-demo)",
   "language": "python",
   "name": "rag-demo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
